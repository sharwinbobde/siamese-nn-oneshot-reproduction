{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "siamese.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "machine_shape": "hm"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2cT7lOrijlJs",
    "colab_type": "text"
   },
   "source": [
    "# Reproducing Omniglot experiment in the Siamese NNs for One Shot Recognition Paper\n",
    "\n",
    "In this notebook we reproduce Table 1 in the original \n",
    "[Siamese NN Paper](https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf)\n",
    "\n",
    "[Original MSc Thesis](http://www.cs.toronto.edu/~gkoch/files/msc-thesis.pdf).\n",
    "\n",
    "We start from this [code](https://github.com/sorenbouma/keras-oneshot) implemented in Keras and try to translate it to use the PyTorch library\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Twhmbb8kXNQ",
    "colab_type": "text"
   },
   "source": [
    "\n",
    "--------------------------------\n",
    "# How/Why Siamese Networks Work\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5M1FkjdQluR8",
    "colab_type": "text"
   },
   "source": [
    "# One-Shot Image Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qac1GqFnl58c",
    "colab_type": "text"
   },
   "source": [
    "# Experiment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Mcpj2P3l8So",
    "colab_type": "text"
   },
   "source": [
    "# Running the experiment on Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-uAN_OrVe3HD",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uoqpb1oxoEpU",
    "colab_type": "text"
   },
   "source": [
    "## Definition of the dataset class that will hold our examples"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Rtx4GZl_oJy-",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "class SiameseDataset(data.Dataset):\n",
    "    \"\"\"Dataset that reads the data from an npy file and \n",
    "    returns a pair to the loader\"\"\"\n",
    "    def __init__(self, data_path=None, labels_path=None, \n",
    "                 transform=None, dataset: data.Dataset =None, \n",
    "                 data : np.ndarray = None, labels: np.ndarray = None,\n",
    "                 mean : float = None, std : float = None,\n",
    "                 transform_data=False):\n",
    "        self.transform_data = transform_data\n",
    "\n",
    "        # If we're given another dataset, just take that\n",
    "        if dataset is not None:\n",
    "            self.data = dataset.data\n",
    "            self.labels = dataset.labels\n",
    "            self.transforms = dataset.transforms\n",
    "\n",
    "        # We can also pass the data and labels as an array\n",
    "        elif data is not None:\n",
    "            self.data = data\n",
    "            self.labels = labels\n",
    "            self.transforms = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "            ])\n",
    "\n",
    "        # If not, that means that we load it from a file\n",
    "        else:\n",
    "            # Load the data and labels\n",
    "            self.data = np.load(data_path)\n",
    "            self.labels = np.load(labels_path)\n",
    "\n",
    "            # for training set, calculate mean and std\n",
    "            # to normalize\n",
    "            if mean == None and std == None:\n",
    "                # stats of the dataset\n",
    "                self.mean = np.mean(self.data[:,:,:])\n",
    "                self.std = np.std(self.data[:,:,:])\n",
    "            # for test set, use mean and std from\n",
    "            # the train set to normalize\n",
    "            else:\n",
    "                self.mean = mean\n",
    "                self.std = std\n",
    "            # Normalize by default!\n",
    "            self.normalize = transforms.Normalize(mean=(self.mean,),\n",
    "                                                std = (self.std,))\n",
    "            # We apply the transformations that are given, so we can \n",
    "            # join the datasets\n",
    "\n",
    "            if transform is not None:\n",
    "              # If we're given transforms it means\n",
    "              # that we're trying to apply the affine transformations\n",
    "              self.transforms = transforms.Compose([\n",
    "                  transform, \n",
    "                  transforms.ToTensor(),\n",
    "              ])\n",
    "            else:\n",
    "              # If we're not given transforms just return the\n",
    "              # normalized tensor\n",
    "              print(\"Using the default transformations\")\n",
    "              self.transforms = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    self.normalize                                \n",
    "              ])\n",
    "              \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def get_images(self, index):\n",
    "        _x1 = self.data[index,0,:,:]\n",
    "        _x2 = self.data[index,1,:,:]\n",
    "        label = self.labels[index]\n",
    "        return Image.fromarray(_x1), Image.fromarray(_x2), label\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" Gets the next pair from \n",
    "        the dataset and its corresponding label\n",
    "        (0 or 1 depending on if they're the same\n",
    "        or a different letter)\"\"\"\n",
    "        _x1 = self.data[index,0,:,:]\n",
    "        _x2 = self.data[index,1,:,:]\n",
    "        label = self.labels[index]\n",
    "        \n",
    "        # Convert to PIL Images so \n",
    "        # we can transform them with affine transforms\n",
    "        # Just needed to generate the dataset\n",
    "        if self.transform_data:\n",
    "            _x1 = Image.fromarray(_x1)\n",
    "            _x2 = Image.fromarray(_x2)\n",
    "            \n",
    "            # we need to convert the x's to images to apply the transforms\n",
    "            return self.transforms(_x1), self.transforms(_x2), label\n",
    "        else:\n",
    "          # We're trying to train the dataset, so give\n",
    "          # the data in float32 version that's better for training\n",
    "          # and apply the ToTensor and normalization transformations\n",
    "            _x1 = _x1.astype(np.float32)\n",
    "            _x2 = _x2.astype(np.float32)\n",
    "            label = label.astype(np.float32)\n",
    "            return self.transforms(_x1), self.transforms(_x2), label\n",
    "    \n",
    "# Some easy functions to visualize the data \n",
    "def show_pair(x1, x2, lab):\n",
    "    \"\"\"Function to show two images of the dataset side by side\"\"\"\n",
    "    # x1 = x1.numpy()\n",
    "    # x2 = x2.numpy()\n",
    "    f ,(ax1, ax2) = plt.subplots(1, 2, sharey= True)\n",
    "    ax1.imshow(x1.squeeze())\n",
    "    ax2.imshow(x2.squeeze())\n",
    "    plt.show()\n",
    "    print('same' if lab == 1 else 'different')\n",
    "    \n",
    "def show_image_pair(i1, i2, lab):\n",
    "    f ,(ax1, ax2) = plt.subplots(1, 2, sharey= True)\n",
    "    ax1.imshow(i1)\n",
    "    ax2.imshow(i2)\n",
    "    plt.show()\n",
    "    print('same' if lab == 1 else 'different')\n",
    "    "
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5aSgUcaaokfH",
    "colab_type": "text"
   },
   "source": [
    "### Set up the folder in Google Drive and define the data path"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "c6auieDfogWa",
    "colab_type": "code",
    "outputId": "17b8d3c0-39ca-44b1-c048-8ba1d55a04cf",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    }
   },
   "source": [
    "import os\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "!ls \"/content/drive/My Drive/Siamese/\"\n",
    "\n",
    "# Change the current directory to the path so it's more comfortable to work\n",
    "path = \"/content/drive/My Drive/Siamese/\"\n",
    "os.chdir(path)"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
      "trainX_30k.npy\ttrainY_30k.npy\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Bug6aTZxosI4",
    "colab_type": "code",
    "outputId": "8ed83f0f-0f47-43b5-882e-1c00a4adfaa6",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# define the paths of the data from the work dir\n",
    "data_path = \"trainX_30k.npy\"\n",
    "labels_path = \"trainY_30k.npy\"\n",
    "\n",
    "# Affine transformations to be done on the data\n",
    "affine = transforms.RandomAffine(degrees = (-10,10), \n",
    "                                 translate=(0.2,0.2),\n",
    "                                 scale = (0.8, 1.2),\n",
    "                                 shear = (-0.3, 0.3), \n",
    "                                 fillcolor=255)\n",
    "\n",
    "\n",
    "# Create a dataset with the 30K examples without\n",
    "# affine tranbsformations \n",
    "d = SiameseDataset(data_path, labels_path)\n",
    "\n",
    "# In order to augment the dataset the dataset has to be created with\n",
    "# some extra parameters and call the function defined below\n",
    "# d = SiameseDataset(data_path, labels_path, transform_data=True, transform=affine)\n",
    "# print(\"Loaded data\")\n",
    "# d = augment_dataset(d)"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Using the default transformations\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q4ioF-p-sxTg",
    "colab_type": "text"
   },
   "source": [
    "## In case we want to augment the dataset we can run the function defined below\n",
    "\n",
    "For each sample the fucntion generates 8x affine transformed samples of that pair and returns a new dataset with the original images and the augmented samples"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RGt6Iyi7rSLH",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# In case we want to create affine transformations...\n",
    "import gc\n",
    "\n",
    "\n",
    "def augment_dataset(d: SiameseDataset) -> SiameseDataset:\n",
    "  \"\"\" Augments the dataset and returns a siamese dataset\n",
    "  with 9x as much data, the original data in the argument dataset\n",
    "  plus 8 affine transformations of that input data\"\"\"\n",
    "  # Create a data loader of the dataset\n",
    "  loader = data.DataLoader(d, batch_size=15000)\n",
    "\n",
    "  # Altered samples of the input data\n",
    "  _altered = None\n",
    "\n",
    "  # Check the size of the batches and so on\n",
    "  # Read in batches of 15000, and do it \n",
    "  for j in range(8):\n",
    "      gc.collect()\n",
    "      print(\"starting with round \",j)\n",
    "      for i, (x1, x2, _) in enumerate(loader):\n",
    "          if i % 1 == 0:\n",
    "              print(i)\n",
    "          # concatenate the arrays by their second axis\n",
    "          _data = np.concatenate((x1.numpy().astype(np.uint8), x2.numpy().astype(np.uint8)), axis = 1)\n",
    "          # add them to the dataset\n",
    "          if _altered is None:\n",
    "              _altered = _data\n",
    "          else:\n",
    "              # Concatenate the existing data and the new batch\n",
    "              _altered = np.concatenate((_altered, _data), axis = 0)\n",
    "      \n",
    "      print(f'Size of the datasets -> {_altered.shape}')\n",
    "\n",
    "  # Now create a new dataset with the newly defined data\n",
    "  # Concatenate the original dataset with the new one\n",
    "  all_data = np.concatenate((d.data, _altered), axis = 0)\n",
    "  labels = np.tile(d.labels, 9)\n",
    "  d = SiameseDataset(data = all_data, labels = labels)\n",
    "  return d"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DPlU4gaHlY5t",
    "colab_type": "text"
   },
   "source": [
    "-------------------------------------\n",
    "## Definition of the network architecture"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "IsEL_whslWv5",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "class ConvNet(nn.Module):\n",
    "  \"\"\" Convolutional NN used in pair inside the siamese Network \"\"\"\n",
    "  def __init__(self):\n",
    "    super(ConvNet, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(1, 64, 10)\n",
    "    self.pool = nn.MaxPool2d(2, 2)\n",
    "    self.conv2 = nn.Conv2d(64, 128, 7)\n",
    "    self.conv3 = nn.Conv2d(128,128,4)\n",
    "    self.conv4 = nn.Conv2d(128,256, 4)\n",
    "    self.fc1 = nn.Linear(256*6*6, 4096)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    out = self.pool(F.relu(self.conv1(x)))\n",
    "    out = self.pool(F.relu(self.conv2(out)))\n",
    "    out = self.pool(F.relu(self.conv3(out)))\n",
    "    out = F.relu(self.conv4(out))\n",
    "    out = out.view(-1, 256*6*6)\n",
    "    # We get the h feature vectors\n",
    "    out = F.sigmoid(self.fc1(out))\n",
    "    return out\n",
    "\n",
    "class SiameseNet(nn.Module):\n",
    "  \"\"\"Siamese Net combining two ConvNets\"\"\"\n",
    "  def __init__(self, net):\n",
    "    # Receives a net as a parameter, we can just have 1 net \n",
    "    # but do the forward pass twice! and then just update once, much more \n",
    "    # elegant\n",
    "    super(SiameseNet, self).__init__()\n",
    "    # Instantiate two of the same class\n",
    "    self.convnet = net\n",
    "    # Final layer and output\n",
    "    self.prediction_layer = nn.Linear(4096,1)\n",
    "\n",
    "  def forward(self,x1, x2):\n",
    "    \"\"\"Computes the forward given two images\"\"\"\n",
    "    h1 = self.convnet(x1)\n",
    "    h2 = self.convnet(x2)\n",
    "    h = self.calculate_l1_distance(h1, h2)\n",
    "    out = F.sigmoid(self.prediction_layer(h))\n",
    "    return out\n",
    "  \n",
    "  def calculate_l1_distance(self, h1, h2):\n",
    "    \"\"\"Calculates l1 distance between the two given vectors\"\"\"\n",
    "    return torch.abs(h1-h2)\n",
    "\n",
    "\n",
    "# How to initialize the weights according to the paper\n",
    "def weights_init(model):\n",
    "  if isinstance(model, nn.Conv2d):\n",
    "    nn.init.normal_(model.weight, mean = 0.0, std = 1e-2)\n",
    "    nn.init.normal_(model.bias, mean=0.5, std = 1e-2)\n",
    "  elif isinstance(model, nn.Linear):\n",
    "    nn.init.normal_(model.weight, mean= 0.0, std = 0.2)\n",
    "    nn.init.normal_(model.bias, mean=0.5, std = 1e-2)\n",
    "\n"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qj8AwypRYxFe",
    "colab_type": "text"
   },
   "source": [
    "### Create the Siamese Network and Initialize weights according to specifications\n",
    "- Conv layers: \n",
    "  - Weights: Normal(0, 1e-2)\n",
    "  - Bias: Normal(0.5, 1e-2)\n",
    "- Linear layers: \n",
    "  - Weights: Normal(0, 0.2)\n",
    "  - Bias: Normal(0.5, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9zPtfP3AUfhj",
    "colab_type": "code",
    "outputId": "63b8ef94-63b5-4e9b-9dcc-aa1af8430da7",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "conv = ConvNet()\n",
    "siamese = SiameseNet(conv)\n",
    "siamese.apply(weights_init)"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "SiameseNet(\n  (convnet): ConvNet(\n    (conv1): Conv2d(1, 64, kernel_size=(10, 10), stride=(1, 1))\n    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (conv2): Conv2d(64, 128, kernel_size=(7, 7), stride=(1, 1))\n    (conv3): Conv2d(128, 128, kernel_size=(4, 4), stride=(1, 1))\n    (conv4): Conv2d(128, 256, kernel_size=(4, 4), stride=(1, 1))\n    (fc1): Linear(in_features=9216, out_features=4096, bias=True)\n  )\n  (prediction_layer): Linear(in_features=4096, out_features=1, bias=True)\n)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 5
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4P_10kSyZO0p",
    "colab_type": "text"
   },
   "source": [
    "### Define the Loss (CrossEntropy) and the Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jAlxZADgYuMN",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "import torch.optim as optim\n",
    "# Learning rate decay per epoch\n",
    "lr_decay_rate = 0.99\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# We shouls change the momentum as the network trains, right now it's to low\n",
    "optimizer = optim.SGD(siamese.parameters(), lr = 0.1, momentum=0.7, weight_decay=2e-4)\n",
    "#optimizer = optim.Adam(siamese.parameters(), lr = 0.01, weight_decay = 2e-4)\n",
    "optim_scheduler = optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma = lr_decay_rate)\n"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OtINTkF9mZUC",
    "colab_type": "text"
   },
   "source": [
    "---\n",
    "## Hyperparameter Setting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bj8kcukdmc5b",
    "colab_type": "text"
   },
   "source": [
    "---------------------------------\n",
    "## Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "AfozeCIjo1iZ",
    "colab_type": "code",
    "outputId": "8ce11dde-fecb-4a50-9750-d31679edd383",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Send the network to the GPU if available\n",
    "#device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "siamese.to(device)\n",
    "\n",
    "# define the loader of the dataset\n",
    "train_loader = data.DataLoader(d, batch_size=128, shuffle=True)\n",
    "\n",
    "for epoch in range(100):\n",
    "  running_loss = 0.0\n",
    "  i = 0\n",
    "  \n",
    "  for X1, X2, y in train_loader:\n",
    "    X1 = X1.to(device)\n",
    "    X2 = X2.to(device)\n",
    "    y = y.to(device)\n",
    "    \n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    X1 = X1.view(-1, 1, 105, 105)\n",
    "    X2 = X2.view(-1, 1, 105, 105)\n",
    "    y = y.view(-1,1)\n",
    "\n",
    "    \n",
    "\n",
    "    outputs = siamese(X1, X2)\n",
    "    #print(outputs.max(), outputs.min())\n",
    "    \n",
    "    loss = criterion(outputs , y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # print statistics\n",
    "    running_loss += loss.item()\n",
    "    if i % 20 == 0:\n",
    "      print('[%d, %5d] loss: %.3f lr: %.5f' %\n",
    "                (epoch + 1, i + 1, running_loss / (i+1), optimizer.param_groups[0]['lr']))\n",
    "    i+=1\n",
    "  # Update the learning rate\n",
    "  optim_scheduler.step()\n",
    "    \n",
    "  \n"
   ],
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "c:\\users\\diego_000\\cs\\dl_project\\venv_dl\\lib\\site-packages\\torch\\nn\\functional.py:1350: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "[1,     1] loss: 0.693 lr: 0.10000\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-76b23073b05f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;31m#print(outputs.max(), outputs.min())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\diego_000\\cs\\dl_project\\venv_dl\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\diego_000\\cs\\dl_project\\venv_dl\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    496\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 498\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\diego_000\\cs\\dl_project\\venv_dl\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[1;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   2049\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2050\u001b[0m     return torch._C._nn.binary_cross_entropy(\n\u001b[1;32m-> 2051\u001b[1;33m         input, target, weight, reduction_enum)\n\u001b[0m\u001b[0;32m   2052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ],
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cI4oWq6bmz5Z",
    "colab_type": "text"
   },
   "source": [
    "---\n",
    "## Running the Experiment"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kzjP2BRqhCSN",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Read the dataset"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8gDe5nYvhFQc",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": 0,
   "outputs": []
  }
 ]
}