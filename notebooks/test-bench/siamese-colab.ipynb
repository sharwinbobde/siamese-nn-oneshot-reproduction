{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "siamese-colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sharwinbobde/siamese-nn-oneshot-reproduction/blob/validation-and-fix/notebooks/test-bench/siamese-colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cT7lOrijlJs",
        "colab_type": "text"
      },
      "source": [
        "# Reproducing Omniglot experiment in the Siamese NNs for One Shot Recognition Paper\n",
        "\n",
        "In this notebook we reproduce Table 1 in the original \n",
        "[Siamese NN Paper](https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf)\n",
        "\n",
        "[Original MSc Thesis](http://www.cs.toronto.edu/~gkoch/files/msc-thesis.pdf).\n",
        "\n",
        "We start from this [code](https://github.com/sorenbouma/keras-oneshot) implemented in Keras and try to translate it to use the PyTorch library\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Mcpj2P3l8So",
        "colab_type": "text"
      },
      "source": [
        "# Running the experiment on Google Colab\n",
        "\n",
        "First import the libraries necessary to run and define our Siamese NN implementation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uAN_OrVe3HD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchsummary import summary\n",
        "\n",
        "from torch.utils import data\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoqpb1oxoEpU",
        "colab_type": "text"
      },
      "source": [
        "## Definition of the dataset class that will hold our examples\n",
        "\n",
        "We define a special dataset that will hold our samples and labels. Tha dataset has certaion functionality that varies depending on the parameters used:\n",
        "\n",
        "1. Create a dataset based on input files\n",
        "2. Create a dataset given another dataset\n",
        "3. Create a dataset given the numpy arrays of the data and the labels\n",
        "4. Define extra transformations: \n",
        "  - In case no transformations are given the images are just transformed into Tensors and normalized\n",
        "  - In case we provide some affine transformations the dataset outputs random transformed images instead of the originals. If we want to transform the dataset we need to record and save these modified images and then put them in another dataset with transformations turned off so the images are consistent across runs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rtx4GZl_oJy-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SiameseDataset(data.Dataset):\n",
        "    \"\"\"Dataset that reads the data from an npy file and \n",
        "    returns a pair to the loader\"\"\"\n",
        "    def __init__(self, data_path=None, labels_path=None, \n",
        "                 transform=None, dataset: data.Dataset =None, \n",
        "                 data : np.ndarray = None, labels: np.ndarray = None,\n",
        "                 mean : float = None, std : float = None,\n",
        "                 transform_data=False):\n",
        "        self.transform_data = transform_data\n",
        "\n",
        "        # If we're given another dataset, just take that\n",
        "        if dataset is not None:\n",
        "            self.data = dataset.data\n",
        "            self.labels = dataset.labels\n",
        "            self.transforms = dataset.transforms\n",
        "\n",
        "        # We can also pass the data and labels as an array\n",
        "        elif data is not None:\n",
        "            self.data = data\n",
        "            self.labels = labels\n",
        "\n",
        "            self.mean = mean\n",
        "            self.std = std \n",
        "\n",
        "            \n",
        "            self.normalize = transforms.Normalize(mean=(self.mean,),\n",
        "                                                std = (self.std,))\n",
        "            self.transforms = transforms.Compose([\n",
        "                transforms.ToTensor(),\n",
        "                self.normalize\n",
        "            ])\n",
        "\n",
        "        # If not, that means that we load it from a file\n",
        "        else:\n",
        "            # Load the data and labels\n",
        "            self.data = np.load(data_path)\n",
        "            self.labels = np.load(labels_path)\n",
        "\n",
        "            # for training set, calculate mean and std\n",
        "            # to normalize\n",
        "            if mean == None and std == None:\n",
        "                # stats of the dataset\n",
        "                self.mean = np.mean(self.data[:,:,:])\n",
        "                self.std = np.std(self.data[:,:,:])\n",
        "            # for test set, use mean and std from\n",
        "            # the train set to normalize\n",
        "            else:\n",
        "                self.mean = mean\n",
        "                self.std = std\n",
        "            # Normalize by default!\n",
        "            self.normalize = transforms.Normalize(mean=(self.mean,),\n",
        "                                                std = (self.std,))\n",
        "            # We apply the transformations that are given, so we can \n",
        "            # join the datasets\n",
        "\n",
        "            if transform is not None:\n",
        "              # If we're given transforms it means\n",
        "              # that we're trying to apply the affine transformations\n",
        "              self.transforms = transforms.Compose([\n",
        "                  transform\n",
        "              ])\n",
        "            else:\n",
        "              # If we're not given transforms just return the\n",
        "              # normalized tensor\n",
        "              print(\"Using the default transformations\")\n",
        "              self.transforms = transforms.Compose([\n",
        "                    transforms.ToTensor(),\n",
        "                    self.normalize                                \n",
        "              ])\n",
        "              \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def get_images(self, index):\n",
        "        _x1 = self.data[index,0,:,:]\n",
        "        _x2 = self.data[index,1,:,:]\n",
        "        label = self.labels[index]\n",
        "        return Image.fromarray(_x1), Image.fromarray(_x2), label\n",
        "        \n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        \"\"\" Gets the next pair from \n",
        "        the dataset and its corresponding label\n",
        "        (0 or 1 depending on if they're the same\n",
        "        or a different letter)\"\"\"\n",
        "        _x1 = self.data[index,0,:,:]\n",
        "        _x2 = self.data[index,1,:,:]\n",
        "        label = self.labels[index]\n",
        "        \n",
        "        # Convert to PIL Images so \n",
        "        # we can transform them with affine transforms\n",
        "        # Just needed to generate the dataset\n",
        "        if self.transform_data:\n",
        "            _x1 = Image.fromarray(_x1)\n",
        "            _x2 = Image.fromarray(_x2)\n",
        "            \n",
        "            # we need to convert the x's to images to apply the transforms\n",
        "            return np.array(self.transforms(_x1)), np.array(self.transforms(_x2)), label\n",
        "        else:\n",
        "          # We're trying to train the dataset, so give\n",
        "          # the data in float32 version that's better for training\n",
        "          # and apply the ToTensor and normalization transformations\n",
        "            _x1 = _x1.astype(np.float32)\n",
        "            _x2 = _x2.astype(np.float32)\n",
        "            label = label.astype(np.float32)\n",
        "            return self.transforms(_x1), self.transforms(_x2), label\n",
        "    \n",
        "# Some easy functions to visualize the data \n",
        "def show_pair(x1, x2, lab):\n",
        "    \"\"\"Function to show two images of the dataset side by side\"\"\"\n",
        "    # x1 = x1.numpy()\n",
        "    # x2 = x2.numpy()\n",
        "    f ,(ax1, ax2) = plt.subplots(1, 2, sharey= True)\n",
        "    ax1.imshow(x1.squeeze())\n",
        "    ax2.imshow(x2.squeeze())\n",
        "    plt.show()\n",
        "    print('same' if lab == 1 else 'different')\n",
        "    \n",
        "def show_image_pair(i1, i2, lab):\n",
        "    f ,(ax1, ax2) = plt.subplots(1, 2, sharey= True)\n",
        "    ax1.imshow(i1)\n",
        "    ax2.imshow(i2)\n",
        "    plt.show()\n",
        "    print('same' if lab == 1 else 'different')\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aSgUcaaokfH",
        "colab_type": "text"
      },
      "source": [
        "### Set up the folder in Google Drive and define the data path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6auieDfogWa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "!ls \"/content/drive/My Drive/Deep Learning Q3\"\n",
        "\n",
        "# Change the current directory to the path so it's more comfortable to work\n",
        "path = \"/content/drive/My Drive/Deep Learning Q3\"\n",
        "os.chdir(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4ioF-p-sxTg",
        "colab_type": "text"
      },
      "source": [
        "## Define the workflow for Dataset Augmentation\n",
        "\n",
        "In case we wish to augment a given dataset we just need to pass said dataset to this function. It will take care of:\n",
        "1. Creating 8x affine transformations of the original images\n",
        "2. Computing the mean and std of the resulting dataset\n",
        "3. Returning a concatenated version of the original dataset and the one with the transformed images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGt6Iyi7rSLH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# In case we want to create affine transformations...\n",
        "import gc\n",
        "\n",
        "\n",
        "def augment_dataset(d: SiameseDataset) -> SiameseDataset:\n",
        "  \"\"\" Augments the dataset and returns a siamese dataset\n",
        "  with 9x as much data, the original data in the argument dataset\n",
        "  plus 8 affine transformations of that input data\"\"\"\n",
        "  # Create a data loader of the dataset\n",
        "  loader = data.DataLoader(d, batch_size=15000)\n",
        "\n",
        "  # Altered samples of the input data\n",
        "  _altered = None\n",
        "  mean = None\n",
        "  std = None\n",
        "\n",
        "  # Check the size of the batches and so on\n",
        "  # Read in batches of 15000, and do it \n",
        "  for j in range(8):\n",
        "      gc.collect()\n",
        "      print(\"starting with round \",j)\n",
        "      for i, (x1, x2, _) in enumerate(loader):\n",
        "          if i % 1 == 0:\n",
        "              print(i)\n",
        "          x1 = np.expand_dims(x1, 1)\n",
        "          x2 = np.expand_dims(x2, 1)\n",
        "          # concatenate the arrays by their second axis\n",
        "          _data = np.concatenate((x1,x2), axis = 1)\n",
        "          _mean = np.mean(_data)\n",
        "          _std = np.std(_data)\n",
        "          if mean is None:\n",
        "            mean = _mean\n",
        "            std = _std\n",
        "          else:\n",
        "            mean = (mean*len(_altered) +  _mean*len(_data))/(len(_altered)+len(_data))\n",
        "            std = (std*len(_altered) +  _std*len(_data))/(len(_altered)+len(_data))\n",
        "          # add them to the dataset\n",
        "          if _altered is None:\n",
        "              _altered = _data\n",
        "          else:\n",
        "              # Concatenate the existing data and the new batch\n",
        "              _altered = np.concatenate((_altered, _data), axis = 0)\n",
        "      \n",
        "      print(f'Size of the datasets -> {_altered.shape}')\n",
        "\n",
        "  # Now create a new dataset with the newly defined data\n",
        "  # Concatenate the original dataset with the new one\n",
        "  all_data = np.concatenate((d.data, _altered), axis = 0)\n",
        "  labels = np.tile(d.labels, 9)\n",
        "  # Add mean of the original datset\n",
        "  mean = (mean*len(_altered) +  d.mean*len(d))/(len(_altered)+len(d))\n",
        "  std = (std*len(_altered) +  d.std*len(d))/(len(_altered)+len(d))\n",
        "  d = SiameseDataset(data = all_data, labels = labels, mean = mean, std = std)\n",
        "  return d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkzkzXACLghZ",
        "colab_type": "text"
      },
      "source": [
        "## Load the different datasets form the files\n",
        "\n",
        "We load the training, validation and test data from their respective files.\n",
        "\n",
        "In case we want to transform the dataset we create the training dataset with the affine transformations and `transform_data=True` so that it outputs altered images, and call the function defined above.\n",
        "\n",
        "(With larger datasets calculating the mean and variance when creating them can cause OOM error, for that reason we approximate by inputing the mean and variance of another training dataset so that step is ommited)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bug6aTZxosI4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the paths of the training data\n",
        "train_data_path = \"datasets/trainX_150k.npy\"\n",
        "train_labels_path = \"datasets/trainY_150k.npy\"\n",
        "\n",
        "# Affine transformations to be done on the train data\n",
        "affine = transforms.RandomAffine(degrees = (-10,10), \n",
        "                                 translate=(0.1,0.1),\n",
        "                                 scale = (0.8, 1.2),\n",
        "                                 shear = (-0.3, 0.3), \n",
        "                                 fillcolor=255)\n",
        "\n",
        "# Create the dataset without affine transformations\n",
        "# Mean of the 270k dataset 236.26801215923408\n",
        "# std of the 270k dataset 66.52629108400019\n",
        "train_d = SiameseDataset(train_data_path, train_labels_path, \n",
        "                         mean = 236.26801215923408, std = 66.52629108400019)\n",
        "\n",
        "\n",
        "# In case we want to augment the dataset we would run the two lines \n",
        "# below instead:\n",
        "# train_d = SiameseDataset(train_data_path, train_labels_path, \n",
        "#                          transform_data=True, transform=affine)\n",
        "# train_d = augment_dataset(train_d)\n",
        "\n",
        "\n",
        "# Print the statistics of the dataset\n",
        "print(f\"Mean of {train_d.mean} and {train_d.std}\")\n",
        "print(\"Loaded data\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L09YjjbD9Ia1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the validation data\n",
        "valid_data_path = \"datasets/validationX.npy\"\n",
        "valid_labels_path = \"datasets/validationY.npy\"\n",
        "\n",
        "valid_d = SiameseDataset(valid_data_path, valid_labels_path)\n",
        "\n",
        "# Print the statistics of the dataset\n",
        "print(\"Loaded validation set with shape \",valid_d.data.shape)\n",
        "print(f\"Mean of {valid_d.mean} and {valid_d.std}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7HZCDcU5aVe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the test data\n",
        "test_data_path = \"datasets/testX.npy\"\n",
        "test_labels_path = \"datasets/testY.npy\"\n",
        "\n",
        "test_d = SiameseDataset(test_data_path, test_labels_path)\n",
        "\n",
        "# Print the statistics of the dataset\n",
        "print(\"Loaded test set with shape \",test_d.data.shape)\n",
        "print(f\"Mean of {test_d.mean} and {test_d.std}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPlU4gaHlY5t",
        "colab_type": "text"
      },
      "source": [
        "-------------------------------------\n",
        "## Definition of the network architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsEL_whslWv5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is the CNN that will be used within the Siamese Network \n",
        "# to calculate the similarity score.\n",
        "# It ouputs a 4096 flat representation of the image that will be used \n",
        "# later in the output layer of the whole Siamese Network\n",
        "class ConvNet(nn.Module):\n",
        "  \"\"\" Convolutional NN used in pair inside the siamese Network \"\"\"\n",
        "  def __init__(self):\n",
        "    super(ConvNet, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 64, 10)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.conv2 = nn.Conv2d(64, 128, 7)\n",
        "    self.conv3 = nn.Conv2d(128,128,4)\n",
        "    self.conv4 = nn.Conv2d(128,256, 4)\n",
        "    self.fc1 = nn.Linear(256*6*6, 4096)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    out = self.pool(F.relu(self.conv1(x)))\n",
        "    out = self.pool(F.relu(self.conv2(out)))\n",
        "    out = self.pool(F.relu(self.conv3(out)))\n",
        "    out = F.relu(self.conv4(out))\n",
        "    out = out.view(-1, 256*6*6)\n",
        "    # We get the h feature vectors\n",
        "    out = torch.sigmoid(self.fc1(out))\n",
        "    return out\n",
        "\n",
        "\n",
        "# Siamese network that wraps the convnet and performs the computations \n",
        "# of the final layer so we have a similarity score as an output\n",
        "class SiameseNet(nn.Module):\n",
        "  \"\"\"Siamese Net combining two ConvNets\"\"\"\n",
        "  def __init__(self, net):\n",
        "    super(SiameseNet, self).__init__()\n",
        "    # Instantiate the convnet\n",
        "    self.convnet = net\n",
        "    # Final layer and output\n",
        "    self.prediction_layer = nn.Linear(4096,1)\n",
        "\n",
        "  def forward(self,x1, x2):\n",
        "    \"\"\"Computes the forward given two images\"\"\"\n",
        "    # We use the same convnet twice with the same \n",
        "    # weights and store the outputs. \n",
        "    # It's another way of simmulating having two networks\n",
        "    h1 = self.convnet(x1)\n",
        "    h2 = self.convnet(x2)\n",
        "    h = self.calculate_l1_distance(h1, h2)\n",
        "    out = self.prediction_layer(h)\n",
        "    # We don't perform the sigmoid here but include it \n",
        "    # in the BCE with logits for numerical stability\n",
        "    # Without the Log-sum-exp trick it underflows quite regularly\n",
        "    return out\n",
        "  \n",
        "  def calculate_l1_distance(self, h1, h2):\n",
        "    \"\"\"Calculates l1 distance between the two given vectors\"\"\"\n",
        "    return torch.abs(h1-h2)\n",
        "\n",
        "\n",
        "torch.manual_seed(12)\n",
        "\n",
        "# How to initialize the weights according to the paper\n",
        "def weights_init(model):\n",
        "  np.random.seed(12)\n",
        "  if isinstance(model, nn.Conv2d):\n",
        "    nn.init.normal_(model.weight, mean = 0.0, std = 1e-2)\n",
        "    nn.init.normal_(model.bias, mean=0.5, std = 1e-2)\n",
        "  elif isinstance(model, nn.Linear):\n",
        "    nn.init.normal_(model.weight, mean= 0.0, std = 0.2)\n",
        "    nn.init.normal_(model.bias, mean=0.5, std = 1e-2)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qj8AwypRYxFe",
        "colab_type": "text"
      },
      "source": [
        "### Create the Siamese Network and Initialize weights according to specifications\n",
        "- Conv layers: \n",
        "  - Weights: Normal(0, 1e-2)\n",
        "  - Bias: Normal(0.5, 1e-2)\n",
        "- Linear layers: \n",
        "  - Weights: Normal(0, 0.2)\n",
        "  - Bias: Normal(0.5, 1e-2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zPtfP3AUfhj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the siamese network and initialize the weights\n",
        "conv = ConvNet()\n",
        "siamese = SiameseNet(conv)\n",
        "siamese.apply(weights_init)\n",
        "\n",
        "# Send the network to the GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
        "siamese.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtINTkF9mZUC",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "## Hyperparameter Setting \n",
        "\n",
        "We use the Adam optimizer with different weight decays for the internal Convnet layers and for the final output layer from the siamese network\n",
        "\n",
        "We use a constant small LR of 3e-4 for the entire network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjJzC3Q3lgRa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "learning_rate = 3e-4\n",
        "regularization = 2e-4\n",
        "\n",
        "optimizer = optim.Adam(\n",
        "    [\n",
        "     {\"params\": siamese.convnet.parameters()},\n",
        "     {\"params\": siamese.prediction_layer.parameters(), \"weight_decay\": 1e-3}\n",
        "    ],\n",
        "    lr = learning_rate,\n",
        "    weight_decay = regularization\n",
        ")\n",
        "\n",
        "n_epochs = 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4P_10kSyZO0p",
        "colab_type": "text"
      },
      "source": [
        "### Define the Loss (CrossEntropy) and the Adam optimizer\n",
        "\n",
        "We set two different weight decay rates as done in the keras code, as it certainly shows really good results this way, as well as a fixed (could be reduced in the future) learning rate of 3e-4 using the Adam Optimizer\n",
        "\n",
        "We choose BCEWithLogits in order to improve the stability of teh network compared to when we use just BCE, since it makes use of the log sum exp trick thus avoiding underflow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAlxZADgYuMN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bj8kcukdmc5b",
        "colab_type": "text"
      },
      "source": [
        "---------------------------------\n",
        "## Training and Validation\n",
        "\n",
        "Definition of the train and validation loops. We perform basic operations and print the results of the forward passes every N iterations to track the performance.\n",
        "\n",
        "We choose to validate every round and save the best model yet to disk so it can be loaded again for the validation loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfozeCIjo1iZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, train_data_loader, validate_data_loader,\n",
        "          model_save_path, checkpoint_path,\n",
        "          validate_every = 10 , save_every = 50):\n",
        "  \"\"\" Train the network with two parameters, one is how often should we validate\n",
        "  and the other is how often should we save a checkpoint\"\"\"\n",
        "\n",
        "  best_accuracy = 0\n",
        "\n",
        "  # define the loader of the dataset\n",
        "\n",
        "\n",
        "  for epoch in range(n_epochs):\n",
        "    running_loss = 0.0\n",
        "    i = 0\n",
        "    \n",
        "    for X1, X2, y in train_data_loader:\n",
        "      # set network to learning mode\n",
        "      model.train()\n",
        "\n",
        "      # send to gpu\n",
        "      X1 = X1.to(device)\n",
        "      X2 = X2.to(device)\n",
        "      y = y.to(device)\n",
        "      \n",
        "      # make gradients zero before forward prop\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # reshape inputs\n",
        "      X1 = X1.view(-1, 1, 105, 105)\n",
        "      X2 = X2.view(-1, 1, 105, 105)\n",
        "      y = y.view(-1, 1)\n",
        "\n",
        "      # forward prop\n",
        "      outputs = model(X1, X2)\n",
        "\n",
        "      # compute loss\n",
        "      loss = criterion(outputs, y)\n",
        "\n",
        "      # backprop and gradient descent step\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # print statistics\n",
        "      running_loss += loss.item()\n",
        "      if i % 50 == 0:\n",
        "        print('[%d, %5d] loss: %.3f lr: %.5f' %\n",
        "                  (epoch + 1, i + 1, running_loss / (i+1), optimizer.param_groups[0]['lr']))\n",
        "      i+=1\n",
        "\n",
        "    # Update the learning rate\n",
        "    # optim_scheduler.step()\n",
        "\n",
        "    # every `validate_every` epochs,\n",
        "    # get metrics from validation set\n",
        "    if epoch % validate_every == 0:\n",
        "      accuracy = validate(model, validate_data_loader)\n",
        "\n",
        "      # if accuracy is higest till now,\n",
        "      # save model\n",
        "      if accuracy > best_accuracy:\n",
        "        print(\"Saving best model\")\n",
        "        best_accuracy = accuracy\n",
        "        torch.save(model.state_dict(), model_save_path)\n",
        "\n",
        "    # save model every `save_every` epochs\n",
        "    if epoch > 0 and epoch % save_every == 0:\n",
        "      torch.save(model.state_dict(), checkpoint_path)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkbTiqs7MlZ2",
        "colab_type": "text"
      },
      "source": [
        "## Validation Loop\n",
        "\n",
        "In this validation loop we loop through the validation set and calculate the accuracy of the model.\n",
        "\n",
        "We can do this as often as it is said in the training loop. For a thorough evaluation we can use validate_every= 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABqSLMQRCUys",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validate(model, data_loader):\n",
        "  \"\"\" Validates the model and computes the accuracy\"\"\"\n",
        "  \n",
        "  # set network to validation mode\n",
        "  model.eval()\n",
        "  print(\"Validating model!\")\n",
        "\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "    for x1, x2, y in data_loader:\n",
        "\n",
        "      # Send data to device\n",
        "      x1 = x1.to(device)\n",
        "      x2= x2.to(device)\n",
        "      y = y.to(device)\n",
        "\n",
        "      # Appropriate view\n",
        "      x1 = x1.view(-1, 1, 105, 105)\n",
        "      x2 = x2.view(-1, 1, 105, 105)\n",
        "      y = y.view(-1,1)\n",
        "\n",
        "      # forward prop\n",
        "      outputs = model(x1, x2)\n",
        "      # Translate the outputs to 0 or 1\n",
        "      predicted = torch.round(torch.sigmoid(outputs))\n",
        "\n",
        "      total += y.size(0)\n",
        "      correct += (predicted == y).sum().item()\n",
        "    \n",
        "    # return the accuracy\n",
        "    print(\"Accuracy of the network on the val set %.3f %%\" % (100*correct /total))\n",
        "    return 100*correct/total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cI4oWq6bmz5Z",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "## Running the Experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XANF2TNnfJb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define where the model will be saved to persistent storage\n",
        "model_save_path = os.path.join(\"saved_models\", \"best.th\")\n",
        "checkpoint_path = os.path.join(\"saved_models\", \"checkpoint.th\")\n",
        "\n",
        "# Create the data loaders from the training and validation set\n",
        "train_loader = data.DataLoader(train_d, batch_size=128, shuffle=True, pin_memory=True, num_workers=4)\n",
        "val_loader = data.DataLoader(valid_d, shuffle=True, batch_size=128, pin_memory=True, num_workers=4)\n",
        "\n",
        "# Train the model\n",
        "train(siamese, train_loader, val_loader, model_save_path, checkpoint_path, validate_every=1) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sebOdYR32Pg",
        "colab_type": "text"
      },
      "source": [
        "# Validating on the Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vf68u8z0q8XE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load best model for testing\n",
        "model_save_path = os.path.join(\"saved_models\", \"best270k.th\")\n",
        "siamese.load_state_dict(torch.load(model_save_path, map_location=device))\n",
        "# create data loader for test set\n",
        "test_loader = data.DataLoader(test_d, shuffle=True, batch_size=128, pin_memory=True, num_workers=4)\n",
        "\n",
        "# Here we can validate on the val_loader or test_loader\n",
        "validate(siamese, val_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ttcoZUT765L",
        "colab_type": "text"
      },
      "source": [
        "# One-Shot task\n",
        "\n",
        "Below we show the special structures and tasks needed to conduct the oneshot task.\n",
        "1. We define a oneshot dataset that returns ready-made batches or subset for the one-shot task\n",
        "2. We define the loop that iterates through all the subsets of the dataset and checks the one-shot accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNp5Ddlv5zaq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a specific oneshot dataset since the dimensionality\n",
        "# of the data is a bit special and different from the traditional\n",
        "# siamese dataset\n",
        "class OneShotDataset(data.Dataset):\n",
        "  def __init__(self, data_path, labels_path, mean = None, std = None):\n",
        "    # Data is 400 x set_size x 2 x H x W\n",
        "    # We use the set size as a batch size\n",
        "    self.data = np.load(data_path)\n",
        "    self.labels = np.load(labels_path)\n",
        "\n",
        "    # Calculate the mean for normalization if not \n",
        "    # given\n",
        "    if mean is None:\n",
        "      self.mean = np.mean(self.data)\n",
        "      self.std = np.std(self.data)\n",
        "    else:\n",
        "      self.mean = mean\n",
        "      self.std = std\n",
        "    \n",
        "    # Define the transformations \n",
        "    self.normalize = transforms.Normalize(mean = (self.mean,),\n",
        "                                          std = (self.std, ))\n",
        "    self.transforms = transforms.Compose([\n",
        "                                          self.normalize\n",
        "    ])\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  # When trying to get data items return the tensor and normalize\n",
        "  # We need for every batch to extract the test image and the subset \n",
        "  # and return X1, X2 and labels with X1 and X2 being (20x105x105) and\n",
        "  # the labels being (20x1)\n",
        "  def __getitem__(self, index):\n",
        "    batches = self.data[index]\n",
        "    x1 = torch.Tensor(batches[:,0, :, :].reshape(20,105, 105).astype(np.float32))\n",
        "    x2 = torch.Tensor(batches[:,1, :, :].reshape(20,105,105).astype(np.float32))\n",
        "    \n",
        "    labels = torch.Tensor(self.labels[index].astype(np.float32))\n",
        "    return self.transforms(x1), self.transforms(x2), labels\n",
        "\n",
        "  def get_images(self, index):\n",
        "    batches = self.data[index]\n",
        "    x1 = batches[:,0, :, :][0]\n",
        "    x2 = batches[:,1, :, :]\n",
        "    label = self.labels[index]\n",
        "    return Image.fromarray(x1), [Image.fromarray(i) for i in x2], label\n",
        "\n",
        "# Visualize the images returned by the loader\n",
        "def show_oneshot_pair(x1, x2, lab):\n",
        "    \"\"\"Function to show two images of the dataset side by side\"\"\"\n",
        "    x1 = x1 *oneshot_d.std + oneshot_d.mean\n",
        "    x2 = x2 *oneshot_d.std + oneshot_d.mean\n",
        "    x1 = x1.numpy()\n",
        "    x2 = x2.numpy()\n",
        "    f ,(ax1, ax2) = plt.subplots(1, 2, sharey= True)\n",
        "    ax1.imshow(x1.squeeze())\n",
        "    ax2.imshow(x2.squeeze())\n",
        "    plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fJPZUu-EtVj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test the argmax of the network output is the same \n",
        "# to the one of the labels\n",
        "def oneshot_test(model, data_loader):\n",
        "  model.eval()\n",
        "\n",
        "  print(\"Oneshot testing!\")\n",
        "\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "    for x1, x2, y in data_loader:\n",
        "\n",
        "      # Send data to device\n",
        "      x1 = x1.to(device)\n",
        "      x2= x2.to(device)\n",
        "      y = y.to(device)\n",
        "\n",
        "      # Appropriate view\n",
        "      x1 = x1.view(-1, 1, 105, 105)\n",
        "      x2 = x2.view(-1, 1, 105, 105)\n",
        "      y = y.view(-1,1)\n",
        "\n",
        "      # forward prop\n",
        "      outputs = torch.sigmoid(model(x1, x2))\n",
        "      # Translate the outputs to 0 or 1\n",
        "\n",
        "      # Check accuracy for this batch\n",
        "      total += 1\n",
        "      if torch.argmax(outputs) == torch.argmax(y):\n",
        "        correct += 1\n",
        "    \n",
        "    # return the accuracy\n",
        "    print(\"Accuracy of the network on the oneshot set %.3f %%\" % (100*correct /total))\n",
        "    return 100*correct/total\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvfXpVte79a6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the dataset from storage\n",
        "oneshot_data_path = \"datasets/X_oneshot.npy\"\n",
        "oneshot_labels_path = \"datasets/Y_oneshot.npy\"\n",
        "oneshot_d = OneShotDataset(oneshot_data_path, oneshot_labels_path)\n",
        "\n",
        "# Print statistics\n",
        "print(\"Loaded oneshot set with shape \",oneshot_d.data.shape)\n",
        "print(f\"Mean of {oneshot_d.mean} and {oneshot_d.std}\")\n",
        "\n",
        "# load best model for testing\n",
        "model_save_path = os.path.join(\"saved_models\", \"best270k.th\")\n",
        "siamese.load_state_dict(torch.load(model_save_path, map_location=device))\n",
        "\n",
        "# create the loader\n",
        "oneshot_loader = data.DataLoader(oneshot_d, shuffle=False, batch_size=1, pin_memory=True)\n",
        "\n",
        "# test the output\n",
        "oneshot_test(siamese, oneshot_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAXQQQ7tqxsZ",
        "colab_type": "text"
      },
      "source": [
        "## Some code to visualize all the examples of the task\n",
        "\n",
        "Shows all the pairs of images considered inside a batch and their similarity score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvcO9Wte9WkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = iter(oneshot_loader)\n",
        "a.next()\n",
        "a.next()\n",
        "x1, x2, y = a.next()\n",
        "\n",
        "print(x1.shape)\n",
        "# Appropriate view\n",
        "x1 = x1.view(-1, 1, 105, 105)\n",
        "x2 = x2.view(-1, 1, 105, 105)\n",
        "y = y.view(-1,1)\n",
        "\n",
        "outputs = torch.sigmoid(siamese(x1.cuda(), x2.cuda()))\n",
        "\n",
        "\n",
        "\n",
        "for i in range(x1.shape[0]):\n",
        "  show_oneshot_pair(x1[i], x2[i], y[i])\n",
        "  print(outputs[i].item())\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}