{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "siamese-colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sharwinbobde/siamese-nn-oneshot-reproduction/blob/validation-and-fix/notebooks/test-bench/siamese-colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cT7lOrijlJs",
        "colab_type": "text"
      },
      "source": [
        "# Reproducing Omniglot experiment in the Siamese NNs for One Shot Recognition Paper\n",
        "\n",
        "In this notebook we reproduce Table 1 in the original \n",
        "[Siamese NN Paper](https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf)\n",
        "\n",
        "[Original MSc Thesis](http://www.cs.toronto.edu/~gkoch/files/msc-thesis.pdf).\n",
        "\n",
        "We start from this [code](https://github.com/sorenbouma/keras-oneshot) implemented in Keras and try to translate it to use the PyTorch library\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Twhmbb8kXNQ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "--------------------------------\n",
        "# How/Why Siamese Networks Work\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5M1FkjdQluR8",
        "colab_type": "text"
      },
      "source": [
        "# One-Shot Image Recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qac1GqFnl58c",
        "colab_type": "text"
      },
      "source": [
        "# Experiment Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Mcpj2P3l8So",
        "colab_type": "text"
      },
      "source": [
        "# Running the experiment on Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uAN_OrVe3HD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchsummary import summary\n",
        "\n",
        "from torch.utils import data\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoqpb1oxoEpU",
        "colab_type": "text"
      },
      "source": [
        "## Definition of the dataset class that will hold our examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rtx4GZl_oJy-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SiameseDataset(data.Dataset):\n",
        "    \"\"\"Dataset that reads the data from an npy file and \n",
        "    returns a pair to the loader\"\"\"\n",
        "    def __init__(self, data_path=None, labels_path=None, \n",
        "                 transform=None, dataset: data.Dataset =None, \n",
        "                 data : np.ndarray = None, labels: np.ndarray = None,\n",
        "                 mean : float = None, std : float = None,\n",
        "                 transform_data=False):\n",
        "        self.transform_data = transform_data\n",
        "\n",
        "        # If we're given another dataset, just take that\n",
        "        if dataset is not None:\n",
        "            self.data = dataset.data\n",
        "            self.labels = dataset.labels\n",
        "            self.transforms = dataset.transforms\n",
        "\n",
        "        # We can also pass the data and labels as an array\n",
        "        elif data is not None:\n",
        "            self.data = data\n",
        "            self.labels = labels\n",
        "\n",
        "            self.mean = mean\n",
        "            self.std = std \n",
        "\n",
        "            \n",
        "            self.normalize = transforms.Normalize(mean=(self.mean,),\n",
        "                                                std = (self.std,))\n",
        "            self.transforms = transforms.Compose([\n",
        "                transforms.ToTensor(),\n",
        "                self.normalize\n",
        "            ])\n",
        "\n",
        "        # If not, that means that we load it from a file\n",
        "        else:\n",
        "            # Load the data and labels\n",
        "            self.data = np.load(data_path)\n",
        "            self.labels = np.load(labels_path)\n",
        "\n",
        "            # for training set, calculate mean and std\n",
        "            # to normalize\n",
        "            if mean == None and std == None:\n",
        "                # stats of the dataset\n",
        "                self.mean = np.mean(self.data[:,:,:])\n",
        "                self.std = np.std(self.data[:,:,:])\n",
        "            # for test set, use mean and std from\n",
        "            # the train set to normalize\n",
        "            else:\n",
        "                self.mean = mean\n",
        "                self.std = std\n",
        "            # Normalize by default!\n",
        "            self.normalize = transforms.Normalize(mean=(self.mean,),\n",
        "                                                std = (self.std,))\n",
        "            # We apply the transformations that are given, so we can \n",
        "            # join the datasets\n",
        "\n",
        "            if transform is not None:\n",
        "              # If we're given transforms it means\n",
        "              # that we're trying to apply the affine transformations\n",
        "              self.transforms = transforms.Compose([\n",
        "                  transform\n",
        "              ])\n",
        "            else:\n",
        "              # If we're not given transforms just return the\n",
        "              # normalized tensor\n",
        "              print(\"Using the default transformations\")\n",
        "              self.transforms = transforms.Compose([\n",
        "                    transforms.ToTensor(),\n",
        "                    self.normalize                                \n",
        "              ])\n",
        "              \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def get_images(self, index):\n",
        "        _x1 = self.data[index,0,:,:]\n",
        "        _x2 = self.data[index,1,:,:]\n",
        "        label = self.labels[index]\n",
        "        return Image.fromarray(_x1), Image.fromarray(_x2), label\n",
        "        \n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        \"\"\" Gets the next pair from \n",
        "        the dataset and its corresponding label\n",
        "        (0 or 1 depending on if they're the same\n",
        "        or a different letter)\"\"\"\n",
        "        _x1 = self.data[index,0,:,:]\n",
        "        _x2 = self.data[index,1,:,:]\n",
        "        label = self.labels[index]\n",
        "        \n",
        "        # Convert to PIL Images so \n",
        "        # we can transform them with affine transforms\n",
        "        # Just needed to generate the dataset\n",
        "        if self.transform_data:\n",
        "            _x1 = Image.fromarray(_x1)\n",
        "            _x2 = Image.fromarray(_x2)\n",
        "            \n",
        "            # we need to convert the x's to images to apply the transforms\n",
        "            return np.array(self.transforms(_x1)), np.array(self.transforms(_x2)), label\n",
        "        else:\n",
        "          # We're trying to train the dataset, so give\n",
        "          # the data in float32 version that's better for training\n",
        "          # and apply the ToTensor and normalization transformations\n",
        "            _x1 = _x1.astype(np.float32)\n",
        "            _x2 = _x2.astype(np.float32)\n",
        "            label = label.astype(np.float32)\n",
        "            return self.transforms(_x1), self.transforms(_x2), label\n",
        "    \n",
        "# Some easy functions to visualize the data \n",
        "def show_pair(x1, x2, lab):\n",
        "    \"\"\"Function to show two images of the dataset side by side\"\"\"\n",
        "    # x1 = x1.numpy()\n",
        "    # x2 = x2.numpy()\n",
        "    f ,(ax1, ax2) = plt.subplots(1, 2, sharey= True)\n",
        "    ax1.imshow(x1.squeeze())\n",
        "    ax2.imshow(x2.squeeze())\n",
        "    plt.show()\n",
        "    print('same' if lab == 1 else 'different')\n",
        "    \n",
        "def show_image_pair(i1, i2, lab):\n",
        "    f ,(ax1, ax2) = plt.subplots(1, 2, sharey= True)\n",
        "    ax1.imshow(i1)\n",
        "    ax2.imshow(i2)\n",
        "    plt.show()\n",
        "    print('same' if lab == 1 else 'different')\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aSgUcaaokfH",
        "colab_type": "text"
      },
      "source": [
        "### Set up the folder in Google Drive and define the data path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6auieDfogWa",
        "colab_type": "code",
        "outputId": "e52a02a6-b136-41bb-8203-b64b64ecba8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "!ls \"/content/drive/My Drive/Deep Learning Q3\"\n",
        "\n",
        "# Change the current directory to the path so it's more comfortable to work\n",
        "path = \"/content/drive/My Drive/Deep Learning Q3\"\n",
        "os.chdir(path)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n",
            " activation_maps  'Choose a Paper.gdoc'   datasets   saved_models   Seminar\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4ioF-p-sxTg",
        "colab_type": "text"
      },
      "source": [
        "## In case we want to augment the dataset we can run the function defined below\n",
        "\n",
        "For each sample the fucntion generates 8x affine transformed samples of that pair and returns a new dataset with the original images and the augmented samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGt6Iyi7rSLH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# In case we want to create affine transformations...\n",
        "import gc\n",
        "\n",
        "\n",
        "def augment_dataset(d: SiameseDataset) -> SiameseDataset:\n",
        "  \"\"\" Augments the dataset and returns a siamese dataset\n",
        "  with 9x as much data, the original data in the argument dataset\n",
        "  plus 8 affine transformations of that input data\"\"\"\n",
        "  # Create a data loader of the dataset\n",
        "  loader = data.DataLoader(d, batch_size=15000)\n",
        "\n",
        "  # Altered samples of the input data\n",
        "  _altered = None\n",
        "  mean = None\n",
        "  std = None\n",
        "\n",
        "  # Check the size of the batches and so on\n",
        "  # Read in batches of 15000, and do it \n",
        "  for j in range(8):\n",
        "      gc.collect()\n",
        "      print(\"starting with round \",j)\n",
        "      for i, (x1, x2, _) in enumerate(loader):\n",
        "          if i % 1 == 0:\n",
        "              print(i)\n",
        "          x1 = np.expand_dims(x1, 1)\n",
        "          x2 = np.expand_dims(x2, 1)\n",
        "          # concatenate the arrays by their second axis\n",
        "          _data = np.concatenate((x1,x2), axis = 1)\n",
        "          _mean = np.mean(_data)\n",
        "          _std = np.std(_data)\n",
        "          if mean is None:\n",
        "            mean = _mean\n",
        "            std = _std\n",
        "          else:\n",
        "            mean = (mean*len(_altered) +  _mean*len(_data))/(len(_altered)+len(_data))\n",
        "            std = (std*len(_altered) +  _std*len(_data))/(len(_altered)+len(_data))\n",
        "          # add them to the dataset\n",
        "          if _altered is None:\n",
        "              _altered = _data\n",
        "          else:\n",
        "              # Concatenate the existing data and the new batch\n",
        "              _altered = np.concatenate((_altered, _data), axis = 0)\n",
        "      \n",
        "      print(f'Size of the datasets -> {_altered.shape}')\n",
        "\n",
        "  # Now create a new dataset with the newly defined data\n",
        "  # Concatenate the original dataset with the new one\n",
        "  all_data = np.concatenate((d.data, _altered), axis = 0)\n",
        "  labels = np.tile(d.labels, 9)\n",
        "  # Add mean of the original datset\n",
        "  mean = (mean*len(_altered) +  d.mean*len(d))/(len(_altered)+len(d))\n",
        "  std = (std*len(_altered) +  d.std*len(d))/(len(_altered)+len(d))\n",
        "  d = SiameseDataset(data = all_data, labels = labels, mean = mean, std = std)\n",
        "  return d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkzkzXACLghZ",
        "colab_type": "text"
      },
      "source": [
        "## Load the training and validation data\n",
        "\n",
        "In case we want to work with the affine transformations we use the part of the code that calls transform dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bug6aTZxosI4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the paths of the training data\n",
        "train_data_path = \"datasets/trainX_150k.npy\"\n",
        "train_labels_path = \"datasets/trainY_150k.npy\"\n",
        "\n",
        "# Affine transformations to be done on the train data\n",
        "affine = transforms.RandomAffine(degrees = (-10,10), \n",
        "                                 translate=(0.1,0.1),\n",
        "                                 scale = (0.8, 1.2),\n",
        "                                 shear = (-0.3, 0.3), \n",
        "                                 fillcolor=255)\n",
        "\n",
        "train_d = SiameseDataset(train_data_path, train_labels_path)\n",
        "# In order to augment the dataset the dataset has to be created with\n",
        "# some extra parameters and call the function defined below\n",
        "\n",
        "\n",
        "# train_d = SiameseDataset(train_data_path, train_labels_path, transform_data=True, transform=affine)\n",
        "print(f\"Mean of {train_d.mean} and {train_d.std}\")\n",
        "print(\"Loaded data\")\n",
        "# train_d = augment_dataset(train_d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L09YjjbD9Ia1",
        "colab_type": "code",
        "outputId": "b63de166-eb04-47ff-b10d-2e92a2bc356c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# validation data\n",
        "valid_data_path = \"datasets/validationX.npy\"\n",
        "valid_labels_path = \"datasets/validationY.npy\"\n",
        "valid_d = SiameseDataset(valid_data_path, valid_labels_path)\n",
        "print(\"Loaded validation set with shape \",valid_d.data.shape)\n",
        "print(f\"Mean of {valid_d.mean} and {valid_d.std}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using the default transformations\n",
            "Loaded validation set with shape  (10000, 2, 105, 105)\n",
            "Mean of 234.00379959183672 and 70.09415576566917\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7HZCDcU5aVe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "46dd3ce5-68dd-422e-a2dc-cf24f04673f5"
      },
      "source": [
        "# test data\n",
        "test_data_path = \"datasets/testX.npy\"\n",
        "test_labels_path = \"datasets/testY.npy\"\n",
        "test_d = SiameseDataset(test_data_path, test_labels_path)\n",
        "print(\"Loaded test set with shape \",test_d.data.shape)\n",
        "print(f\"Mean of {test_d.mean} and {test_d.std}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using the default transformations\n",
            "Loaded test set with shape  (10000, 2, 105, 105)\n",
            "Mean of 235.4205726530612 and 67.89256217167899\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPlU4gaHlY5t",
        "colab_type": "text"
      },
      "source": [
        "-------------------------------------\n",
        "## Definition of the network architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsEL_whslWv5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvNet(nn.Module):\n",
        "  \"\"\" Convolutional NN used in pair inside the siamese Network \"\"\"\n",
        "  def __init__(self):\n",
        "    super(ConvNet, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 64, 10)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.conv2 = nn.Conv2d(64, 128, 7)\n",
        "    self.conv3 = nn.Conv2d(128,128,4)\n",
        "    self.conv4 = nn.Conv2d(128,256, 4)\n",
        "    self.fc1 = nn.Linear(256*6*6, 4096)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    out = self.pool(F.relu(self.conv1(x)))\n",
        "    out = self.pool(F.relu(self.conv2(out)))\n",
        "    out = self.pool(F.relu(self.conv3(out)))\n",
        "    out = F.relu(self.conv4(out))\n",
        "    out = out.view(-1, 256*6*6)\n",
        "    # We get the h feature vectors\n",
        "    out = torch.sigmoid(self.fc1(out))\n",
        "    return out\n",
        "\n",
        "class SiameseNet(nn.Module):\n",
        "  \"\"\"Siamese Net combining two ConvNets\"\"\"\n",
        "  def __init__(self, net):\n",
        "    # Receives a net as a parameter, we can just have 1 net \n",
        "    # but do the forward pass twice! and then just update once, much more \n",
        "    # elegant\n",
        "    super(SiameseNet, self).__init__()\n",
        "    # Instantiate two of the same class\n",
        "    self.convnet = net\n",
        "    # Final layer and output\n",
        "    self.prediction_layer = nn.Linear(4096,1)\n",
        "\n",
        "  def forward(self,x1, x2):\n",
        "    \"\"\"Computes the forward given two images\"\"\"\n",
        "    h1 = self.convnet(x1)\n",
        "    h2 = self.convnet(x2)\n",
        "    h = self.calculate_l1_distance(h1, h2)\n",
        "    out = self.prediction_layer(h)\n",
        "    return out\n",
        "  \n",
        "  def calculate_l1_distance(self, h1, h2):\n",
        "    \"\"\"Calculates l1 distance between the two given vectors\"\"\"\n",
        "    return torch.abs(h1-h2)\n",
        "\n",
        "torch.manual_seed(12)\n",
        "\n",
        "# How to initialize the weights according to the paper\n",
        "def weights_init(model):\n",
        "  np.random.seed(12)\n",
        "  if isinstance(model, nn.Conv2d):\n",
        "    nn.init.normal_(model.weight, mean = 0.0, std = 1e-2)\n",
        "    nn.init.normal_(model.bias, mean=0.5, std = 1e-2)\n",
        "  elif isinstance(model, nn.Linear):\n",
        "    nn.init.normal_(model.weight, mean= 0.0, std = 0.2)\n",
        "    nn.init.normal_(model.bias, mean=0.5, std = 1e-2)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qj8AwypRYxFe",
        "colab_type": "text"
      },
      "source": [
        "### Create the Siamese Network and Initialize weights according to specifications\n",
        "- Conv layers: \n",
        "  - Weights: Normal(0, 1e-2)\n",
        "  - Bias: Normal(0.5, 1e-2)\n",
        "- Linear layers: \n",
        "  - Weights: Normal(0, 0.2)\n",
        "  - Bias: Normal(0.5, 1e-2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zPtfP3AUfhj",
        "colab_type": "code",
        "outputId": "2ae2eace-5ffe-4cbf-fa16-5339e8dd898d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "conv = ConvNet()\n",
        "siamese = SiameseNet(conv)\n",
        "siamese.apply(weights_init)\n",
        "\n",
        "# Send the network to the GPU if available\n",
        "#device = torch.device(\"cpu\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
        "siamese.to(device)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SiameseNet(\n",
              "  (convnet): ConvNet(\n",
              "    (conv1): Conv2d(1, 64, kernel_size=(10, 10), stride=(1, 1))\n",
              "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (conv2): Conv2d(64, 128, kernel_size=(7, 7), stride=(1, 1))\n",
              "    (conv3): Conv2d(128, 128, kernel_size=(4, 4), stride=(1, 1))\n",
              "    (conv4): Conv2d(128, 256, kernel_size=(4, 4), stride=(1, 1))\n",
              "    (fc1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "  )\n",
              "  (prediction_layer): Linear(in_features=4096, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtINTkF9mZUC",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "## Hyperparameter Setting "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjJzC3Q3lgRa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "learning_rate = 3e-4\n",
        "regularization = 2e-4\n",
        "# Learning rate decay per epoch\n",
        "# lr_decay_rate = 0.9\n",
        "\n",
        "optimizer = optim.Adam(\n",
        "    [\n",
        "     {\"params\": siamese.convnet.parameters()},\n",
        "     {\"params\": siamese.prediction_layer.parameters(), \"weight_decay\": 1e-3}\n",
        "    ],\n",
        "    lr = learning_rate,\n",
        "    weight_decay = regularization\n",
        ")\n",
        "\n",
        "n_epochs = 200\n",
        "# momentum = 0.7"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4P_10kSyZO0p",
        "colab_type": "text"
      },
      "source": [
        "### Define the Loss (CrossEntropy) and the Adam optimizer\n",
        "\n",
        "We set two different weight decay rates as done in the keras code, as it certainly shows really good results this way, as well as a fixed (could be reduced in the future) learning rate of 3e-4 using the Adam Optimizer\n",
        "\n",
        "We choose BCEWithLogits in order to improve the stability of teh network compared to when we use just BCE, since it makes use of the log sum exp trick thus avoiding underflow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAlxZADgYuMN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# We shouls change the momentum as the network trains, right now it's to low\n",
        "#optimizer = optim.SGD(siamese.parameters(), lr = 0.1, momentum=momentum, weight_decay=weight_decay)\n",
        "\n",
        "# optim_scheduler = optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=lr_decay_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bj8kcukdmc5b",
        "colab_type": "text"
      },
      "source": [
        "---------------------------------\n",
        "## Training and Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfozeCIjo1iZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, train_data_loader, validate_data_loader,\n",
        "          model_save_path, checkpoint_path,\n",
        "          validate_every = 10 , save_every = 50):\n",
        "  \"\"\" Train the network with two parameters, one is how often should we validate\n",
        "  and the other is how often should we save a checkpoint\"\"\"\n",
        "\n",
        "  best_accuracy = 0\n",
        "\n",
        "  # define the loader of the dataset\n",
        "\n",
        "\n",
        "  for epoch in range(n_epochs):\n",
        "    running_loss = 0.0\n",
        "    i = 0\n",
        "    \n",
        "    for X1, X2, y in train_data_loader:\n",
        "      # set network to learning mode\n",
        "      model.train()\n",
        "\n",
        "      # send to gpu\n",
        "      X1 = X1.to(device)\n",
        "      X2 = X2.to(device)\n",
        "      y = y.to(device)\n",
        "      \n",
        "      # make gradients zero before forward prop\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # reshape inputs\n",
        "      X1 = X1.view(-1, 1, 105, 105)\n",
        "      X2 = X2.view(-1, 1, 105, 105)\n",
        "      y = y.view(-1, 1)\n",
        "\n",
        "      # forward prop\n",
        "      outputs = model(X1, X2)\n",
        "\n",
        "      # compute loss\n",
        "      loss = criterion(outputs, y)\n",
        "\n",
        "      # backprop and gradient descent step\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # print statistics\n",
        "      running_loss += loss.item()\n",
        "      if i % 50 == 0:\n",
        "        print('[%d, %5d] loss: %.3f lr: %.5f' %\n",
        "                  (epoch + 1, i + 1, running_loss / (i+1), optimizer.param_groups[0]['lr']))\n",
        "      i+=1\n",
        "\n",
        "    # Update the learning rate\n",
        "    # optim_scheduler.step()\n",
        "\n",
        "    # every `validate_every` epochs,\n",
        "    # get metrics from validation set\n",
        "    if epoch % validate_every == 0:\n",
        "      accuracy = validate(model, validate_data_loader)\n",
        "\n",
        "      # if accuracy is higest till now,\n",
        "      # save model\n",
        "      if accuracy > best_accuracy:\n",
        "        print(\"Saving best model\")\n",
        "        best_accuracy = accuracy\n",
        "        torch.save(model.state_dict(), model_save_path)\n",
        "\n",
        "    # save model every `save_every` epochs\n",
        "    if epoch > 0 and epoch % save_every == 0:\n",
        "      torch.save(model.state_dict(), checkpoint_path)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkbTiqs7MlZ2",
        "colab_type": "text"
      },
      "source": [
        "## Validation Loop\n",
        "\n",
        "In this validation loop we loop through the validation set and calculate the accuracy of the model.\n",
        "\n",
        "We can do this as often as it is said in the training loop. For a thorough evaluation we can use validate_every= 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABqSLMQRCUys",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validate(model, data_loader):\n",
        "  \"\"\" Validates the model and computes the accuracy\"\"\"\n",
        "  \n",
        "  # set network to validation mode\n",
        "  model.eval()\n",
        "  print(\"Validating model!\")\n",
        "\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "    for x1, x2, y in data_loader:\n",
        "\n",
        "      # Send data to device\n",
        "      x1 = x1.to(device)\n",
        "      x2= x2.to(device)\n",
        "      y = y.to(device)\n",
        "\n",
        "      # Appropriate view\n",
        "      x1 = x1.view(-1, 1, 105, 105)\n",
        "      x2 = x2.view(-1, 1, 105, 105)\n",
        "      y = y.view(-1,1)\n",
        "\n",
        "      # forward prop\n",
        "      outputs = model(x1, x2)\n",
        "      # Translate the outputs to 0 or 1\n",
        "      predicted = torch.round(torch.sigmoid(outputs))\n",
        "\n",
        "      total += y.size(0)\n",
        "      correct += (predicted == y).sum().item()\n",
        "    \n",
        "    # return the accuracy\n",
        "    print(\"Accuracy of the network on the val set %.3f %%\" % (100*correct /total))\n",
        "    return 100*correct/total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cI4oWq6bmz5Z",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "## Running the Experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XANF2TNnfJb",
        "colab_type": "code",
        "outputId": "11d89aa8-5ef7-497e-abf8-2d2bbceeac85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_save_path = os.path.join(\"saved_models\", \"best150k.th\")\n",
        "checkpoint_path = os.path.join(\"saved_models\", \"checkpoint.th\")\n",
        "\n",
        "train_loader = data.DataLoader(train_d, batch_size=128, shuffle=True, pin_memory=True, num_workers=4)\n",
        "val_loader = data.DataLoader(valid_d, shuffle=True, batch_size=128, pin_memory=True, num_workers=4)\n",
        "\n",
        "train(siamese, train_loader, val_loader, model_save_path, checkpoint_path, validate_every=1) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,     1] loss: 0.721 lr: 0.00030\n",
            "[1,    51] loss: 0.665 lr: 0.00030\n",
            "[1,   101] loss: 0.652 lr: 0.00030\n",
            "[1,   151] loss: 0.652 lr: 0.00030\n",
            "[1,   201] loss: 0.650 lr: 0.00030\n",
            "[1,   251] loss: 0.647 lr: 0.00030\n",
            "[1,   301] loss: 0.643 lr: 0.00030\n",
            "[1,   351] loss: 0.641 lr: 0.00030\n",
            "[1,   401] loss: 0.639 lr: 0.00030\n",
            "[1,   451] loss: 0.636 lr: 0.00030\n",
            "[1,   501] loss: 0.634 lr: 0.00030\n",
            "[1,   551] loss: 0.631 lr: 0.00030\n",
            "[1,   601] loss: 0.628 lr: 0.00030\n",
            "[1,   651] loss: 0.625 lr: 0.00030\n",
            "[1,   701] loss: 0.621 lr: 0.00030\n",
            "Validating model!\n",
            "Accuracy of the network on the val set 74.060 %\n",
            "Saving best model\n",
            "[2,     1] loss: 0.576 lr: 0.00030\n",
            "[2,    51] loss: 0.563 lr: 0.00030\n",
            "[2,   101] loss: 0.563 lr: 0.00030\n",
            "[2,   151] loss: 0.556 lr: 0.00030\n",
            "[2,   201] loss: 0.555 lr: 0.00030\n",
            "[2,   251] loss: 0.551 lr: 0.00030\n",
            "[2,   301] loss: 0.550 lr: 0.00030\n",
            "[2,   351] loss: 0.548 lr: 0.00030\n",
            "[2,   401] loss: 0.546 lr: 0.00030\n",
            "[2,   451] loss: 0.544 lr: 0.00030\n",
            "[2,   501] loss: 0.545 lr: 0.00030\n",
            "[2,   551] loss: 0.544 lr: 0.00030\n",
            "[2,   601] loss: 0.543 lr: 0.00030\n",
            "[2,   651] loss: 0.542 lr: 0.00030\n",
            "[2,   701] loss: 0.541 lr: 0.00030\n",
            "Validating model!\n",
            "Accuracy of the network on the val set 75.580 %\n",
            "Saving best model\n",
            "[3,     1] loss: 0.543 lr: 0.00030\n",
            "[3,    51] loss: 0.515 lr: 0.00030\n",
            "[3,   101] loss: 0.517 lr: 0.00030\n",
            "[3,   151] loss: 0.519 lr: 0.00030\n",
            "[3,   201] loss: 0.521 lr: 0.00030\n",
            "[3,   251] loss: 0.520 lr: 0.00030\n",
            "[3,   301] loss: 0.519 lr: 0.00030\n",
            "[3,   351] loss: 0.519 lr: 0.00030\n",
            "[3,   401] loss: 0.518 lr: 0.00030\n",
            "[3,   451] loss: 0.516 lr: 0.00030\n",
            "[3,   501] loss: 0.516 lr: 0.00030\n",
            "[3,   551] loss: 0.514 lr: 0.00030\n",
            "[3,   601] loss: 0.515 lr: 0.00030\n",
            "[3,   651] loss: 0.514 lr: 0.00030\n",
            "[3,   701] loss: 0.513 lr: 0.00030\n",
            "Validating model!\n",
            "Accuracy of the network on the val set 77.590 %\n",
            "Saving best model\n",
            "[4,     1] loss: 0.504 lr: 0.00030\n",
            "[4,    51] loss: 0.488 lr: 0.00030\n",
            "[4,   101] loss: 0.493 lr: 0.00030\n",
            "[4,   151] loss: 0.494 lr: 0.00030\n",
            "[4,   201] loss: 0.492 lr: 0.00030\n",
            "[4,   251] loss: 0.490 lr: 0.00030\n",
            "[4,   301] loss: 0.490 lr: 0.00030\n",
            "[4,   351] loss: 0.489 lr: 0.00030\n",
            "[4,   401] loss: 0.487 lr: 0.00030\n",
            "[4,   451] loss: 0.486 lr: 0.00030\n",
            "[4,   501] loss: 0.485 lr: 0.00030\n",
            "[4,   551] loss: 0.485 lr: 0.00030\n",
            "[4,   601] loss: 0.484 lr: 0.00030\n",
            "[4,   651] loss: 0.483 lr: 0.00030\n",
            "[4,   701] loss: 0.482 lr: 0.00030\n",
            "Validating model!\n",
            "Accuracy of the network on the val set 79.210 %\n",
            "Saving best model\n",
            "[5,     1] loss: 0.427 lr: 0.00030\n",
            "[5,    51] loss: 0.453 lr: 0.00030\n",
            "[5,   101] loss: 0.455 lr: 0.00030\n",
            "[5,   151] loss: 0.465 lr: 0.00030\n",
            "[5,   201] loss: 0.469 lr: 0.00030\n",
            "[5,   251] loss: 0.468 lr: 0.00030\n",
            "[5,   301] loss: 0.467 lr: 0.00030\n",
            "[5,   351] loss: 0.463 lr: 0.00030\n",
            "[5,   401] loss: 0.461 lr: 0.00030\n",
            "[5,   451] loss: 0.460 lr: 0.00030\n",
            "[5,   501] loss: 0.460 lr: 0.00030\n",
            "[5,   551] loss: 0.460 lr: 0.00030\n",
            "[5,   601] loss: 0.459 lr: 0.00030\n",
            "[5,   651] loss: 0.458 lr: 0.00030\n",
            "[5,   701] loss: 0.457 lr: 0.00030\n",
            "Validating model!\n",
            "Accuracy of the network on the val set 79.830 %\n",
            "Saving best model\n",
            "[6,     1] loss: 0.389 lr: 0.00030\n",
            "[6,    51] loss: 0.438 lr: 0.00030\n",
            "[6,   101] loss: 0.439 lr: 0.00030\n",
            "[6,   151] loss: 0.436 lr: 0.00030\n",
            "[6,   201] loss: 0.437 lr: 0.00030\n",
            "[6,   251] loss: 0.435 lr: 0.00030\n",
            "[6,   301] loss: 0.435 lr: 0.00030\n",
            "[6,   351] loss: 0.434 lr: 0.00030\n",
            "[6,   401] loss: 0.432 lr: 0.00030\n",
            "[6,   451] loss: 0.431 lr: 0.00030\n",
            "[6,   501] loss: 0.430 lr: 0.00030\n",
            "[6,   551] loss: 0.428 lr: 0.00030\n",
            "[6,   601] loss: 0.428 lr: 0.00030\n",
            "[6,   651] loss: 0.426 lr: 0.00030\n",
            "[6,   701] loss: 0.426 lr: 0.00030\n",
            "Validating model!\n",
            "Accuracy of the network on the val set 81.790 %\n",
            "Saving best model\n",
            "[7,     1] loss: 0.477 lr: 0.00030\n",
            "[7,    51] loss: 0.419 lr: 0.00030\n",
            "[7,   101] loss: 0.414 lr: 0.00030\n",
            "[7,   151] loss: 0.410 lr: 0.00030\n",
            "[7,   201] loss: 0.406 lr: 0.00030\n",
            "[7,   251] loss: 0.403 lr: 0.00030\n",
            "[7,   301] loss: 0.401 lr: 0.00030\n",
            "[7,   351] loss: 0.397 lr: 0.00030\n",
            "[7,   401] loss: 0.393 lr: 0.00030\n",
            "[7,   451] loss: 0.391 lr: 0.00030\n",
            "[7,   501] loss: 0.387 lr: 0.00030\n",
            "[7,   551] loss: 0.385 lr: 0.00030\n",
            "[7,   601] loss: 0.382 lr: 0.00030\n",
            "[7,   651] loss: 0.377 lr: 0.00030\n",
            "[7,   701] loss: 0.372 lr: 0.00030\n",
            "Validating model!\n",
            "Accuracy of the network on the val set 86.110 %\n",
            "Saving best model\n",
            "[8,     1] loss: 0.304 lr: 0.00030\n",
            "[8,    51] loss: 0.301 lr: 0.00030\n",
            "[8,   101] loss: 0.293 lr: 0.00030\n",
            "[8,   151] loss: 0.287 lr: 0.00030\n",
            "[8,   201] loss: 0.278 lr: 0.00030\n",
            "[8,   251] loss: 0.271 lr: 0.00030\n",
            "[8,   301] loss: 0.263 lr: 0.00030\n",
            "[8,   351] loss: 0.255 lr: 0.00030\n",
            "[8,   401] loss: 0.249 lr: 0.00030\n",
            "[8,   451] loss: 0.242 lr: 0.00030\n",
            "[8,   501] loss: 0.236 lr: 0.00030\n",
            "[8,   551] loss: 0.230 lr: 0.00030\n",
            "[8,   601] loss: 0.225 lr: 0.00030\n",
            "[8,   651] loss: 0.221 lr: 0.00030\n",
            "[8,   701] loss: 0.216 lr: 0.00030\n",
            "Validating model!\n",
            "Accuracy of the network on the val set 90.750 %\n",
            "Saving best model\n",
            "[9,     1] loss: 0.131 lr: 0.00030\n",
            "[9,    51] loss: 0.121 lr: 0.00030\n",
            "[9,   101] loss: 0.120 lr: 0.00030\n",
            "[9,   151] loss: 0.118 lr: 0.00030\n",
            "[9,   201] loss: 0.115 lr: 0.00030\n",
            "[9,   251] loss: 0.114 lr: 0.00030\n",
            "[9,   301] loss: 0.114 lr: 0.00030\n",
            "[9,   351] loss: 0.113 lr: 0.00030\n",
            "[9,   401] loss: 0.112 lr: 0.00030\n",
            "[9,   451] loss: 0.111 lr: 0.00030\n",
            "[9,   501] loss: 0.109 lr: 0.00030\n",
            "[9,   551] loss: 0.108 lr: 0.00030\n",
            "[9,   601] loss: 0.108 lr: 0.00030\n",
            "[9,   651] loss: 0.106 lr: 0.00030\n",
            "[9,   701] loss: 0.105 lr: 0.00030\n",
            "Validating model!\n",
            "Accuracy of the network on the val set 91.700 %\n",
            "Saving best model\n",
            "[10,     1] loss: 0.048 lr: 0.00030\n",
            "[10,    51] loss: 0.056 lr: 0.00030\n",
            "[10,   101] loss: 0.055 lr: 0.00030\n",
            "[10,   151] loss: 0.055 lr: 0.00030\n",
            "[10,   201] loss: 0.055 lr: 0.00030\n",
            "[10,   251] loss: 0.055 lr: 0.00030\n",
            "[10,   301] loss: 0.056 lr: 0.00030\n",
            "[10,   351] loss: 0.056 lr: 0.00030\n",
            "[10,   401] loss: 0.056 lr: 0.00030\n",
            "[10,   451] loss: 0.057 lr: 0.00030\n",
            "[10,   501] loss: 0.057 lr: 0.00030\n",
            "[10,   551] loss: 0.058 lr: 0.00030\n",
            "[10,   601] loss: 0.058 lr: 0.00030\n",
            "[10,   651] loss: 0.058 lr: 0.00030\n",
            "[10,   701] loss: 0.058 lr: 0.00030\n",
            "Validating model!\n",
            "Accuracy of the network on the val set 92.680 %\n",
            "Saving best model\n",
            "[11,     1] loss: 0.052 lr: 0.00030\n",
            "[11,    51] loss: 0.043 lr: 0.00030\n",
            "[11,   101] loss: 0.041 lr: 0.00030\n",
            "[11,   151] loss: 0.039 lr: 0.00030\n",
            "[11,   201] loss: 0.037 lr: 0.00030\n",
            "[11,   251] loss: 0.037 lr: 0.00030\n",
            "[11,   301] loss: 0.036 lr: 0.00030\n",
            "[11,   351] loss: 0.036 lr: 0.00030\n",
            "[11,   401] loss: 0.036 lr: 0.00030\n",
            "[11,   451] loss: 0.036 lr: 0.00030\n",
            "[11,   501] loss: 0.036 lr: 0.00030\n",
            "[11,   551] loss: 0.037 lr: 0.00030\n",
            "[11,   601] loss: 0.037 lr: 0.00030\n",
            "[11,   651] loss: 0.037 lr: 0.00030\n",
            "[11,   701] loss: 0.038 lr: 0.00030\n",
            "Validating model!\n",
            "Accuracy of the network on the val set 92.530 %\n",
            "[12,     1] loss: 0.016 lr: 0.00030\n",
            "[12,    51] loss: 0.026 lr: 0.00030\n",
            "[12,   101] loss: 0.027 lr: 0.00030\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-a0d734bc78f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mval_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpin_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msiamese\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_save_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-5f5ce539f34a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_data_loader, validate_data_loader, model_save_path, checkpoint_path, validate_every, save_every)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m       \u001b[0;31m# print statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m       \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         print('[%d, %5d] loss: %.3f lr: %.5f' %\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIgZSiFlpTRt",
        "colab_type": "code",
        "outputId": "d061f98b-677f-404b-db6f-d4f3470081d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        }
      },
      "source": [
        "i, j, k = train_d.get_images(90023)\n",
        "show_image_pair(i, j, k)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAC6CAYAAABLCD2TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVMnAAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "same\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sebOdYR32Pg",
        "colab_type": "text"
      },
      "source": [
        "# Validating on the Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vf68u8z0q8XE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "ab1a8132-66a8-4a90-bced-1571469e6a7d"
      },
      "source": [
        "# load best model for testing\n",
        "model_save_path = os.path.join(\"saved_models\", \"best240k.th\")\n",
        "siamese.load_state_dict(torch.load(model_save_path, map_location=device))\n",
        "# create data loader for test set\n",
        "test_loader = data.DataLoader(test_d, shuffle=True, batch_size=128, pin_memory=True, num_workers=4)\n",
        "validate(siamese, test_loader)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validating model!\n",
            "Accuracy of the network on the val set 94.260 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "94.26"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    }
  ]
}